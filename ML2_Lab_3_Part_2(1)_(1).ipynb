{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/joncalle/ML2/blob/main/ML2_Lab_3_Part_2(1)_(1).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Lab 3 Part 2 - Task 1: Parameters in CNN (5 Marks)"
      ],
      "metadata": {
        "id": "VIT-maBq2bbZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Group - 9\n",
        "\n",
        "Danielle do Val Goncalves Tudeia - W0823569\n",
        "\n",
        "Fernanda Barbieri de Camargo - W0825882\n",
        "\n",
        "Jonathan Calle - W0825959\n",
        "\n",
        "Jonathan Chukwuma Oteh - W0775057\n",
        "\n",
        "Luis Patricio Ramirez Fernandez - W0811391"
      ],
      "metadata": {
        "id": "vz-mIxvMMoHD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from google.colab import drive\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Conv2D\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, Flatten, Dense"
      ],
      "metadata": {
        "id": "gt_UdwXfldG4"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- For the model we have created in **Lab 3 Part 1 Exercise**: Early Stopping with Callbacks, calculate the number of parameters by hand for each layer and compare to the output of model.summary() and print the model summary.\n",
        "- Then print the model summary of **Exercise 7 in Lab 1**\n",
        "- Now compare the Model you created in **Exercise 7 in Lab 1**,\n",
        "  - Compare the Parameters of the models\n",
        "\n",
        "  - Compare Model Performance\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "tWo32rVm8TGH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model1 = Sequential([\n",
        "    Conv2D(filters=16,  # Reducing the number of filters in the initial layer\n",
        "           kernel_size=(3, 3),  # Changing filter size to 3x3\n",
        "           strides=1,\n",
        "           padding='same',\n",
        "           activation='relu',\n",
        "           input_shape=(28, 28, 1)),\n",
        "    Conv2D(filters=32,  # Increasing the number of filters in this layer\n",
        "           kernel_size=(3, 3),\n",
        "           strides=2,\n",
        "           padding='valid',\n",
        "           activation='relu'),\n",
        "    Conv2D(filters=64,  # Keeping the same number of filters\n",
        "           kernel_size=(3, 3),\n",
        "           strides=1,\n",
        "           padding='same',\n",
        "           activation='relu'),\n",
        "    Conv2D(filters=128,  # Increasing the number of filters in this layer\n",
        "           kernel_size=(3, 3),\n",
        "           strides=1,\n",
        "           padding='valid',\n",
        "           activation='relu'),\n",
        "    Flatten(),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dense(10, activation='softmax')\n",
        "])"
      ],
      "metadata": {
        "id": "PWci6yrl2Zlg"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model1.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QxF2rSpqmAYX",
        "outputId": "43ba2b7c-ec4d-40db-a245-e8368dc8f955"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 28, 28, 16)        160       \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 13, 13, 32)        4640      \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 13, 13, 64)        18496     \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 11, 11, 128)       73856     \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 15488)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 128)               1982592   \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 10)                1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2081034 (7.94 MB)\n",
            "Trainable params: 2081034 (7.94 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "network8 = Sequential()\n",
        "network8.add(Dense(512, activation='relu', input_shape=(28 * 28,)))\n",
        "network8.add(Dense(64, activation='sigmoid'))\n",
        "network8.add(Dense(10, activation='softmax'))\n",
        "network8.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gl_YFHQXmpgX",
        "outputId": "a1227467-6590-4c9a-f943-0f12876d4618"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_2 (Dense)             (None, 512)               401920    \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 64)                32832     \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 10)                650       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 435402 (1.66 MB)\n",
            "Trainable params: 435402 (1.66 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install cartopy\n",
        "import cartopy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xlsh9dbIqgNy",
        "outputId": "e3d888a0-2987-491f-ff12-1057c48b55a1"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: cartopy in /usr/local/lib/python3.10/dist-packages (0.22.0)\n",
            "Requirement already satisfied: numpy>=1.21 in /usr/local/lib/python3.10/dist-packages (from cartopy) (1.23.5)\n",
            "Requirement already satisfied: matplotlib>=3.4 in /usr/local/lib/python3.10/dist-packages (from cartopy) (3.7.1)\n",
            "Requirement already satisfied: shapely>=1.7 in /usr/local/lib/python3.10/dist-packages (from cartopy) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20 in /usr/local/lib/python3.10/dist-packages (from cartopy) (23.2)\n",
            "Requirement already satisfied: pyshp>=2.1 in /usr/local/lib/python3.10/dist-packages (from cartopy) (2.3.1)\n",
            "Requirement already satisfied: pyproj>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from cartopy) (3.6.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.4->cartopy) (1.1.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.4->cartopy) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.4->cartopy) (4.43.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.4->cartopy) (1.4.5)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.4->cartopy) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.4->cartopy) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.4->cartopy) (2.8.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from pyproj>=3.1.0->cartopy) (2023.7.22)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.4->cartopy) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "maXaHAcw2TsB"
      },
      "source": [
        "# Lab 3 Part 2 - Task 2: CIFAR-10 Challenge (10 Marks)\n",
        "\n",
        "In this lab you will experiment with whatever ConvNet architecture/design you'd like on [CIFAR-10 image dataset](https://www.cs.toronto.edu/~kriz/cifar.html).\n",
        "\n",
        "\n",
        "## Exercise  1: Creating the network\n",
        "\n",
        "**Goal:** After training, your model should achieve **at least 80%** accuracy on a **validation** set within 20 epochs. (Or as close as possible as long as there is demonstrated effort to achieve this goal.)\n",
        "\n",
        "**Data split** The training set should consist of 40000 images, the validation set should consist of 10000 images, and the test set should consist of the remaining 10000 images. **Please use the Keras `load_data()` function to import the data set.**\n",
        "\n",
        "\n",
        "### Some things you can try:\n",
        "- Different number/type of layers\n",
        "- Different filter sizes\n",
        "- Adjust the number of filters used in any given layer\n",
        "- Try various pooling strategies\n",
        "- Consider using batch normalization\n",
        "- Check if adding regularization helps\n",
        "- Consider alternative optimizers\n",
        "- Try different activation functions\n",
        "\n",
        "\n",
        "### Tips for training\n",
        "When building/tuning your model, keep in mind the following points:\n",
        "\n",
        "- This is experimental, so be driven by results achieved on the validation set as opposed to what you have heard/read works well or doesn't\n",
        "- If the hyperparameters are working well, you should see improvement in the loss/accuracy within approximately one epoch\n",
        "- For hyperparameter tuning: start by testing a large range of hyperparameters for just a few training iterations to find the combinations of parameters that are working at all\n",
        "- Once you have found some sets of hyperparameters that seem to work, search more finely around these parameters. You may need to train for more epochs.\n",
        "- Prefer random search to grid search for hyperparameters\n",
        "- You should use the validation set for hyperparameter search and for evaluating different architectures\n",
        "- The test set should only be used at the very end to evaluate your final model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "tIOVFQ0m2TsG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e4ad852-9874-4442-aaa1-4c73a9541d6f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(50000, 32, 32, 3)\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.datasets import cifar10\n",
        "\n",
        "(x_train,y_train),(x_test,y_test) = cifar10.load_data()\n",
        "\n",
        "print(x_train.shape)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mNRWOWnvwb6A",
        "outputId": "b51e5e2a-bff0-4928-cb6f-27aa30334886"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 32, 32, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "\n",
        "# Preprocess the data\n",
        "# - x_train and y_train for training (40,000 images)\n",
        "# - x_validation and y_validation for validation (10,000 images)\n",
        "# - x_test and y_test for testing (10,000 images)\n",
        "x_train = x_train / 255\n",
        "x_test = x_test / 255\n",
        "y_train = to_categorical(y_train)\n",
        "y_test = to_categorical(y_test)\n",
        "\n",
        "# Split the data into training, validation, and test sets\n",
        "x_train, x_validation = x_train[:40000], x_train[40000:50000]\n",
        "y_train, y_validation = y_train[:40000], y_train[40000:50000]"
      ],
      "metadata": {
        "id": "NIQ7HGNxsaNZ"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, BatchNormalization\n",
        "\n",
        "# Create a CNN model\n",
        "model = Sequential([\n",
        "    Conv2D(filters=32, kernel_size=(3, 3), strides=1, padding='same', activation='relu', input_shape=(32, 32, 3)),\n",
        "    Conv2D(filters=64, kernel_size=(3, 3), strides=1, padding='same', activation='relu'),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "    Conv2D(filters=128, kernel_size=(3, 3), strides=1, padding='same', activation='relu'),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "    Flatten(),\n",
        "    Dense(256, activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    Dense(10, activation='softmax')\n",
        "])\n"
      ],
      "metadata": {
        "id": "tO5oh_FBtmbh"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tKyvCOzSuObm",
        "outputId": "3e5e44d9-255f-4df5-b54c-727979e3c77b"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_7 (Conv2D)           (None, 32, 32, 32)        896       \n",
            "                                                                 \n",
            " conv2d_8 (Conv2D)           (None, 32, 32, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPoolin  (None, 16, 16, 64)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_9 (Conv2D)           (None, 16, 16, 128)       73856     \n",
            "                                                                 \n",
            " max_pooling2d_4 (MaxPoolin  (None, 8, 8, 128)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_2 (Flatten)         (None, 8192)              0         \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 256)               2097408   \n",
            "                                                                 \n",
            " batch_normalization (Batch  (None, 256)               1024      \n",
            " Normalization)                                                  \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 10)                2570      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2194250 (8.37 MB)\n",
            "Trainable params: 2193738 (8.37 MB)\n",
            "Non-trainable params: 512 (2.00 KB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "fUc8qP1ruJn_"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "history = model.fit(x_train, y_train,\n",
        "                    validation_data=(x_validation, y_validation), epochs=20,  verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KEbSIz21ugY5",
        "outputId": "002369a3-e3be-4c42-cbb0-4e20a99ba581"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "1563/1563 [==============================] - 12s 8ms/step - loss: 0.0584 - accuracy: 0.9798 - val_loss: 0.0276 - val_accuracy: 0.9906\n",
            "Epoch 2/20\n",
            "1563/1563 [==============================] - 13s 8ms/step - loss: 0.0561 - accuracy: 0.9804 - val_loss: 0.0306 - val_accuracy: 0.9904\n",
            "Epoch 3/20\n",
            "1563/1563 [==============================] - 12s 8ms/step - loss: 0.0532 - accuracy: 0.9816 - val_loss: 0.0395 - val_accuracy: 0.9877\n",
            "Epoch 4/20\n",
            "1563/1563 [==============================] - 12s 7ms/step - loss: 0.0493 - accuracy: 0.9834 - val_loss: 0.0179 - val_accuracy: 0.9943\n",
            "Epoch 5/20\n",
            "1563/1563 [==============================] - 11s 7ms/step - loss: 0.0476 - accuracy: 0.9836 - val_loss: 0.0437 - val_accuracy: 0.9854\n",
            "Epoch 6/20\n",
            "1563/1563 [==============================] - 12s 8ms/step - loss: 0.0484 - accuracy: 0.9834 - val_loss: 0.0789 - val_accuracy: 0.9733\n",
            "Epoch 7/20\n",
            "1563/1563 [==============================] - 12s 7ms/step - loss: 0.0490 - accuracy: 0.9825 - val_loss: 0.0964 - val_accuracy: 0.9744\n",
            "Epoch 8/20\n",
            "1563/1563 [==============================] - 12s 7ms/step - loss: 0.0425 - accuracy: 0.9853 - val_loss: 0.0205 - val_accuracy: 0.9935\n",
            "Epoch 9/20\n",
            "1563/1563 [==============================] - 12s 8ms/step - loss: 0.0442 - accuracy: 0.9848 - val_loss: 0.0332 - val_accuracy: 0.9904\n",
            "Epoch 10/20\n",
            "1563/1563 [==============================] - 12s 7ms/step - loss: 0.0425 - accuracy: 0.9851 - val_loss: 0.0115 - val_accuracy: 0.9973\n",
            "Epoch 11/20\n",
            "1563/1563 [==============================] - 12s 8ms/step - loss: 0.0405 - accuracy: 0.9862 - val_loss: 0.0380 - val_accuracy: 0.9874\n",
            "Epoch 12/20\n",
            "1563/1563 [==============================] - 13s 9ms/step - loss: 0.0372 - accuracy: 0.9872 - val_loss: 0.0406 - val_accuracy: 0.9844\n",
            "Epoch 13/20\n",
            "1563/1563 [==============================] - 12s 7ms/step - loss: 0.0374 - accuracy: 0.9868 - val_loss: 0.0152 - val_accuracy: 0.9953\n",
            "Epoch 14/20\n",
            "1563/1563 [==============================] - 12s 7ms/step - loss: 0.0348 - accuracy: 0.9878 - val_loss: 0.0088 - val_accuracy: 0.9981\n",
            "Epoch 15/20\n",
            "1563/1563 [==============================] - 11s 7ms/step - loss: 0.0351 - accuracy: 0.9882 - val_loss: 0.0135 - val_accuracy: 0.9955\n",
            "Epoch 16/20\n",
            "1563/1563 [==============================] - 12s 7ms/step - loss: 0.0331 - accuracy: 0.9884 - val_loss: 0.0137 - val_accuracy: 0.9955\n",
            "Epoch 17/20\n",
            "1563/1563 [==============================] - 12s 8ms/step - loss: 0.0371 - accuracy: 0.9876 - val_loss: 0.0126 - val_accuracy: 0.9963\n",
            "Epoch 18/20\n",
            "1563/1563 [==============================] - 12s 8ms/step - loss: 0.0275 - accuracy: 0.9904 - val_loss: 0.0820 - val_accuracy: 0.9711\n",
            "Epoch 19/20\n",
            "1563/1563 [==============================] - 12s 8ms/step - loss: 0.0360 - accuracy: 0.9880 - val_loss: 0.0227 - val_accuracy: 0.9924\n",
            "Epoch 20/20\n",
            "1563/1563 [==============================] - 12s 8ms/step - loss: 0.0263 - accuracy: 0.9911 - val_loss: 0.0134 - val_accuracy: 0.9963\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on the test set\n",
        "test_loss, test_accuracy = model.evaluate(x_test, y_test)\n",
        "print(f\"Test Accuracy: {test_accuracy * 100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TXR-2pLzui51",
        "outputId": "3b1b714e-b277-480e-e47f-cf1ff740cd4d"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 1s 4ms/step - loss: 1.6300 - accuracy: 0.7625\n",
            "Test Accuracy: 76.25%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Loss:')\n",
        "history.history['loss']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G3xoUe-W_ows",
        "outputId": "0db00ead-2dbb-4298-9001-3c5e3c778cb9"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.05836986005306244,\n",
              " 0.05612792447209358,\n",
              " 0.05316855385899544,\n",
              " 0.0492868646979332,\n",
              " 0.04757758975028992,\n",
              " 0.04836659133434296,\n",
              " 0.04896816238760948,\n",
              " 0.0424618199467659,\n",
              " 0.044226497411727905,\n",
              " 0.042472198605537415,\n",
              " 0.04052532836794853,\n",
              " 0.037154000252485275,\n",
              " 0.03744646534323692,\n",
              " 0.03477814421057701,\n",
              " 0.03513740003108978,\n",
              " 0.03311305120587349,\n",
              " 0.037125393748283386,\n",
              " 0.027455579489469528,\n",
              " 0.03602997213602066,\n",
              " 0.026269426569342613]"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "64BbG8Y62TsH"
      },
      "source": [
        "## Exercise 2: Describe What you did\n",
        "\n",
        "All the work you did leading up to your final model should be summarized in this section. This should be a logical and well-organized summary of the various experiments that were tried in **Lab 3 Part 2 - Task 2:Exercise 1**, and should be captured in **table format**. Upon reading this section I should understand what you tried, the reasoning behind trying it, any quantitative values that correspond to what you tried, and the results.\n",
        "\n",
        "See [this guide](https://www.datacamp.com/community/tutorials/markdown-in-jupyter-notebook) for how to format markdown cells in Jupyter notebooks."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sa8p0Nkj2TsI"
      },
      "source": [
        "| Data code | Why do we choose the code? | What is the funtion? |\n",
        "| :- | :- | :- |  \n",
        "|   To Normalization   |   Normalizing the pixel values to be in the range of 0 to 1 (usually by dividing by 255) helps in training the neural network. | To ensure that the model doesn't assign too much importance to any one feature (pixel value) and can learn more effectively   |\n",
        "| one-hot encode  |To converts the integer class labels into binary vectors where each vector has a 1 in the position corresponding to the class and zeros in all other positions    | neural network understand that the classes are mutually exclusive, and to  improving the performance of the model during training.  |\n",
        "|  Splitting the data  | Splitting the X_train and the corresponding x_test and y_test for testing    | This data splitting allows you to train and validate the model's performance during training effectively. |\n",
        "| creating the Model  | The model consists of a series of layers: two convolutional layers with 32 and 64 filters, respectively, using a (3, 3) kernel and ReLU activation, followed by max-pooling layers with a (2, 2) pool size; then, another convolutional layer with 128 filters and ReLU activation, followed by max-pooling. After flattening the feature maps, there's a dense layer with 256 neurons and ReLU activation, along with batch normalization, and finally, a dense output layer with 10 neurons using softmax activation.  | The model is to process and classify images using a convolutional neural network with multiple layers, ultimately assigning one of ten possible categories to each input image.|\n",
        "| Compiling the Model | model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy']) | To  configures the neural network for training by specifying the optimizer ('adam'), the loss function ('categorical_crossentropy'), and the evaluation metric ('accuracy').   |\n",
        "| Fitting the model | It is used to train the neural network   |  takes the training data x_train and corresponding labels y_train. The validation_data parameter is used for validation during training. The epochs parameter defines the number of training iterations, and verbose controls the level of output during training (1 for progress updates). The training progress and results are stored in the history variable for later analysis. |\n",
        "|  Evaluating the Model  |  To evaluate the trained neural network on a test dataset, in this case, x_test and y_test  | WHence, It calculates the loss and accuracy of the model's predictions on the test data. The results, including test loss and accuracy, are stored in the variables test_loss and test_accuracy. The final line prints the test accuracy in percentage format with two decimal places.  |"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.13"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
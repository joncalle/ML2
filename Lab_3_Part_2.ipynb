{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/joncalle/ML2/blob/main/Lab_3_Part_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VIT-maBq2bbZ"
      },
      "source": [
        "# Lab 3 Part 2 - Task 1: Parameters in CNN (5 Marks)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tWo32rVm8TGH"
      },
      "source": [
        "- For the model we have created in **Lab 3 Part 1 Exercise**: Early Stopping with Callbacks, calculate the number of parameters by hand for each layer and compare to the output of model.summary() and print the model summary.\n",
        "- Then print the model summary of **Exercise 7 in Lab 1**\n",
        "- Now compare the Model you created in **Exercise 7 in Lab 1**,\n",
        "  - Compare the Parameters of the models\n",
        "\n",
        "  - Compare Model Performance\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "IDLC3N9yP5BM"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, Flatten, Dense, MaxPooling2D\n",
        "import numpy as np\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LZ9l_cYOP5BN",
        "outputId": "5f5f37f5-ed59-47ef-da06-5629499166dc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n",
            "Shape: (28, 28)\n",
            "Train Labels [5 0 4 1 9 2 1 3 1 4]\n"
          ]
        }
      ],
      "source": [
        "# Importing the data\n",
        "(train_data, train_labels), (test_data, test_labels) = mnist.load_data()\n",
        "print('Shape:', train_data[0].shape)\n",
        "print('Train Labels', train_labels[:10])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cg9G5CHRP5BP"
      },
      "outputs": [],
      "source": [
        "# Using the first 10,000 samples of our training data as our validation set\n",
        "val_data, val_labels = train_data[:10000], train_labels[:10000]\n",
        "\n",
        "# Using the remainder of the original training data for actual training\n",
        "partial_train_data, partial_train_labels = train_data[10000:], train_labels[10000:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tSVWuFpLP5BP"
      },
      "outputs": [],
      "source": [
        "# Scaling pixel values so they lie in the range of 0-1\n",
        "partial_train_data = partial_train_data / 255.\n",
        "val_data = val_data / 255.\n",
        "test_data = test_data /255."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GaiQraCLP5BQ"
      },
      "outputs": [],
      "source": [
        "partial_train_data = np.expand_dims(partial_train_data, axis=3)\n",
        "val_data = np.expand_dims(val_data, axis=3)\n",
        "test_data = np.expand_dims(test_data, axis=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aVG7Ly1rP5BQ"
      },
      "outputs": [],
      "source": [
        "partial_train_labels = to_categorical(partial_train_labels)\n",
        "val_labels = to_categorical(val_labels)\n",
        "test_labels = to_categorical(test_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u2mkVk0XP5BR"
      },
      "outputs": [],
      "source": [
        "# Defining the early stopping callback\n",
        "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)\n",
        "\n",
        "# Creating and compiling the model (use your modified model)\n",
        "model3 = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Conv2D(filters=16, kernel_size=(3, 3), strides=1, padding='same', activation='relu', input_shape=(28, 28, 1)),\n",
        "    tf.keras.layers.Conv2D(filters=32, kernel_size=(3, 3), strides=2, padding='valid', activation='relu'),\n",
        "    tf.keras.layers.Conv2D(filters=64, kernel_size=(3, 3), strides=1, padding='same', activation='relu'),\n",
        "    tf.keras.layers.Conv2D(filters=128, kernel_size=(3, 3), strides=1, padding='valid', activation='relu'),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "    tf.keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "model3.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dWWZOM4EP5BS",
        "outputId": "0b41b969-1bcf-4fe7-8854-a67ebca51e42"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "196/196 [==============================] - 44s 218ms/step - loss: 0.2539 - accuracy: 0.9216 - val_loss: 0.1140 - val_accuracy: 0.9656\n",
            "Epoch 2/20\n",
            "196/196 [==============================] - 46s 237ms/step - loss: 0.0525 - accuracy: 0.9837 - val_loss: 0.0541 - val_accuracy: 0.9834\n",
            "Epoch 3/20\n",
            "196/196 [==============================] - 51s 258ms/step - loss: 0.0305 - accuracy: 0.9905 - val_loss: 0.0642 - val_accuracy: 0.9834\n",
            "Epoch 4/20\n",
            "196/196 [==============================] - 53s 269ms/step - loss: 0.0201 - accuracy: 0.9938 - val_loss: 0.0479 - val_accuracy: 0.9882\n",
            "Epoch 5/20\n",
            "196/196 [==============================] - 55s 281ms/step - loss: 0.0142 - accuracy: 0.9955 - val_loss: 0.0562 - val_accuracy: 0.9871\n",
            "Epoch 6/20\n",
            "196/196 [==============================] - 61s 311ms/step - loss: 0.0105 - accuracy: 0.9969 - val_loss: 0.0425 - val_accuracy: 0.9898\n",
            "Epoch 7/20\n",
            "196/196 [==============================] - 59s 299ms/step - loss: 0.0078 - accuracy: 0.9973 - val_loss: 0.0506 - val_accuracy: 0.9895\n",
            "Epoch 8/20\n",
            "196/196 [==============================] - 54s 278ms/step - loss: 0.0055 - accuracy: 0.9984 - val_loss: 0.0529 - val_accuracy: 0.9894\n",
            "Epoch 9/20\n",
            "196/196 [==============================] - 60s 304ms/step - loss: 0.0046 - accuracy: 0.9985 - val_loss: 0.0568 - val_accuracy: 0.9889\n"
          ]
        }
      ],
      "source": [
        "# Fitting the model with the complete training set and use early stopping\n",
        "history3 = model3.fit(\n",
        "    partial_train_data,\n",
        "    partial_train_labels,\n",
        "    epochs=20,\n",
        "    batch_size=256,\n",
        "    validation_data=(val_data, val_labels),\n",
        "    callbacks=[callback],  # Include early stopping\n",
        "    verbose=1  # Set verbose to 0 to avoid printing progress for each epoch\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_V13RlvNP5BS",
        "outputId": "a123dadf-6f7c-4ee2-c78b-d17c29e706f5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 7s 22ms/step - loss: 0.0452 - accuracy: 0.9899\n",
            "Test Loss: 0.045239247381687164\n",
            "Test Accuracy: 0.9898999929428101\n"
          ]
        }
      ],
      "source": [
        "# Evaluating the trained model on the test data\n",
        "test_loss, test_accuracy = model3.evaluate(test_data, test_labels)\n",
        "\n",
        "# Print test loss and accuracy\n",
        "print(f'Test Loss: {test_loss}')\n",
        "print(f'Test Accuracy: {test_accuracy}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PWci6yrl2Zlg",
        "outputId": "41308582-1b79-494e-c3d2-a89e1f7e6834"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_4 (Conv2D)           (None, 28, 28, 16)        160       \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 13, 13, 32)        4640      \n",
            "                                                                 \n",
            " conv2d_6 (Conv2D)           (None, 13, 13, 64)        18496     \n",
            "                                                                 \n",
            " conv2d_7 (Conv2D)           (None, 11, 11, 128)       73856     \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 15488)             0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 128)               1982592   \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 10)                1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2081034 (7.94 MB)\n",
            "Trainable params: 2081034 (7.94 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model3.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "itzSbauAP5BT"
      },
      "outputs": [],
      "source": [
        "# Calculating the parameters by hand - Lab 3 Part 1\n",
        "layer1 = np.array([28,28,16]) #padding is same so the output height and width is the same of input, just the filter number is added\n",
        "layer2 = np.array([np.floor((((28+(2*0)-3)/2)+1)),np.floor((((28+(2*0)-3)/2)+1)),32])\n",
        "layer3 = layer2 + np.array([0,0,(64-32)])#padding is same so the output height and width is the same of previous layer, just the filter number changes\n",
        "layer4 = np.array([np.floor((((13+(2*0)-3)/1)+1)),np.floor((((13+(2*0)-3)/1)+1)),128])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "64Q0L0XOP5BT",
        "outputId": "01c2248f-f07d-4cd5-99dd-9bb43f2768b9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layer 1: [28 28 16]\n",
            "Layer 2: [13. 13. 32.]\n",
            "Layer 3: [13. 13. 64.]\n",
            "Layer 4: [ 11.  11. 128.]\n"
          ]
        }
      ],
      "source": [
        "# Exhibting the parameters calculated by hand - Lab 3 Part 1\n",
        "print(f'Layer 1: {layer1}')\n",
        "print(f'Layer 2: {layer2}')\n",
        "print(f'Layer 3: {layer3}')\n",
        "print(f'Layer 4: {layer4}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KalfjZVrP5BU",
        "outputId": "40450051-d467-4f44-b9c6-88964997bdda"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_4 (Dense)             (None, 512)               401920    \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 64)                32832     \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 10)                650       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 435402 (1.66 MB)\n",
            "Trainable params: 435402 (1.66 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# Summary for Lab 1 - Exercise 7\n",
        "network8 = Sequential()\n",
        "network8.add(Dense(512, activation='relu', input_shape=(28 * 28,)))\n",
        "network8.add(Dense(64, activation='sigmoid'))\n",
        "network8.add(Dense(10, activation='softmax'))\n",
        "network8.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TMsmjZM-P5BU"
      },
      "source": [
        "The accuracy of model created in Lab 1 - Exercise 7 is:\n",
        "New test accuracy: 0.9829999804496765"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VLkJJ5agP5BV"
      },
      "source": [
        "##### Comparing the models:\n",
        "The model we created in Lab 3 part 1 using convolution layers has more then 2 million parameters, this is almost 5 times the number of parameters we had for the model we created in Lab 1 exercise 7 using only dense layers. However, the accuracy of the model in Lab 3 is higher, achieving 98,98% against 98.29% from the pervious model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "maXaHAcw2TsB"
      },
      "source": [
        "# Lab 3 Part 2 - Task 2: CIFAR-10 Challenge (10 Marks)\n",
        "\n",
        "In this lab you will experiment with whatever ConvNet architecture/design you'd like on [CIFAR-10 image dataset](https://www.cs.toronto.edu/~kriz/cifar.html).\n",
        "\n",
        "\n",
        "## Exercise  1: Creating the network\n",
        "\n",
        "**Goal:** After training, your model should achieve **at least 80%** accuracy on a **validation** set within 20 epochs. (Or as close as possible as long as there is demonstrated effort to achieve this goal.)\n",
        "\n",
        "**Data split** The training set should consist of 40000 images, the validation set should consist of 10000 images, and the test set should consist of the remaining 10000 images. **Please use the Keras `load_data()` function to import the data set.**\n",
        "\n",
        "\n",
        "### Some things you can try:\n",
        "- Different number/type of layers\n",
        "- Different filter sizes\n",
        "- Adjust the number of filters used in any given layer\n",
        "- Try various pooling strategies\n",
        "- Consider using batch normalization\n",
        "- Check if adding regularization helps\n",
        "- Consider alternative optimizers\n",
        "- Try different activation functions\n",
        "\n",
        "\n",
        "### Tips for training\n",
        "When building/tuning your model, keep in mind the following points:\n",
        "\n",
        "- This is experimental, so be driven by results achieved on the validation set as opposed to what you have heard/read works well or doesn't\n",
        "- If the hyperparameters are working well, you should see improvement in the loss/accuracy within approximately one epoch\n",
        "- For hyperparameter tuning: start by testing a large range of hyperparameters for just a few training iterations to find the combinations of parameters that are working at all\n",
        "- Once you have found some sets of hyperparameters that seem to work, search more finely around these parameters. You may need to train for more epochs.\n",
        "- Prefer random search to grid search for hyperparameters\n",
        "- You should use the validation set for hyperparameter search and for evaluating different architectures\n",
        "- The test set should only be used at the very end to evaluate your final model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "tIOVFQ0m2TsG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aa20f5e5-94d5-4f6b-a75b-6959337fa4c4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170498071/170498071 [==============================] - 2s 0us/step\n",
            "Shape: (32, 32, 3)\n",
            "Train Labels [[6]\n",
            " [9]\n",
            " [9]\n",
            " [4]\n",
            " [1]\n",
            " [1]\n",
            " [2]\n",
            " [7]\n",
            " [8]\n",
            " [3]]\n"
          ]
        }
      ],
      "source": [
        "# Accessing the images\n",
        "(train_data, train_labels), (test_data, test_labels) = tf.keras.datasets.cifar10.load_data()\n",
        "print('Shape:', train_data[0].shape)\n",
        "print('Train Labels', train_labels[:10])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "DCdcGaLNP5BV"
      },
      "outputs": [],
      "source": [
        "# Using the first 10,000 samples of our training data as our validation set\n",
        "val_data, val_labels = train_data[:10000], train_labels[:10000]\n",
        "\n",
        "# Using 40,000 of the original training data for actual training\n",
        "partial_train_data, partial_train_labels = train_data[10000:50000], train_labels[10000:50000]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "owFzlWTNP5BW"
      },
      "outputs": [],
      "source": [
        "# Scaling pixel values so they lie in the range of 0-1\n",
        "partial_train_data = partial_train_data / 255.\n",
        "val_data = val_data / 255.\n",
        "test_data = test_data /255."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RHt62yu_P5BW",
        "outputId": "99ed3ee5-e218-41d6-d129-7592f48a5cad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(40000, 32, 32, 3)\n",
            "(10000, 32, 32, 3)\n",
            "(10000, 32, 32, 3)\n"
          ]
        }
      ],
      "source": [
        "print(partial_train_data.shape)\n",
        "print(val_data.shape)\n",
        "print(test_data.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "qHpBsiECP5BW"
      },
      "outputs": [],
      "source": [
        "# Adjusting the data labels\n",
        "partial_train_labels = to_categorical(partial_train_labels)\n",
        "val_labels = to_categorical(val_labels)\n",
        "test_labels = to_categorical(test_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "UzNz8x7dP5BW"
      },
      "outputs": [],
      "source": [
        "# Model\n",
        "model = Sequential([\n",
        "    Conv2D(filters=96,\n",
        "           kernel_size=(3, 3),\n",
        "           strides=1,\n",
        "           padding='same',\n",
        "           activation='relu',\n",
        "           input_shape=(32, 32, 3)),\n",
        "    Conv2D(filters=96,\n",
        "           kernel_size=(3, 3),\n",
        "           strides=2,\n",
        "           padding='valid',\n",
        "           activation='relu'),\n",
        "    MaxPooling2D(pool_size = 3,\n",
        "                 strides = 1),\n",
        "    Conv2D(filters=96,\n",
        "           kernel_size=(3, 3),\n",
        "           strides=1,\n",
        "           padding='same',\n",
        "          activation='relu'),\n",
        "    Conv2D(filters=96,\n",
        "           kernel_size=(3, 3),\n",
        "           strides=1,\n",
        "           padding='same',\n",
        "          activation='relu'),\n",
        "    MaxPooling2D(pool_size = 3,\n",
        "                 strides = 1),\n",
        "    Conv2D(filters=192,\n",
        "           kernel_size=(3, 3),\n",
        "           strides=1,\n",
        "           padding='valid',\n",
        "           activation='relu'),\n",
        "    Conv2D(filters=192,\n",
        "           kernel_size=(3, 3),\n",
        "           strides=1,\n",
        "           padding='valid',\n",
        "           activation='relu'),\n",
        "    MaxPooling2D(pool_size = 3,\n",
        "                 strides = 1),\n",
        "    Flatten(),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dense(10, activation='softmax')\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "p-S5B4OaP5BW"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='rmsprop',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MjlHA7fiP5BX",
        "outputId": "26d8205b-e721-4808-8e1f-4681e27bf49a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "124/267 [============>.................] - ETA: 4:27 - loss: 2.2554 - accuracy: 0.1746"
          ]
        }
      ],
      "source": [
        "model.fit(partial_train_data,\n",
        "          partial_train_labels,\n",
        "          epochs=20,\n",
        "          batch_size=150,\n",
        "          validation_data=(val_data, val_labels),\n",
        "          verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_A-O2yrUP5BX"
      },
      "outputs": [],
      "source": [
        "history.history['loss']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E-j5GqJCP5BX",
        "outputId": "1d1ea04c-a8d2-4dba-bab2-a34ac9822075"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 8s 25ms/step - loss: 1.3412 - accuracy: 0.5252\n",
            "Test Loss: 1.341245412826538\n",
            "Test Accuracy: 0.5252000093460083\n"
          ]
        }
      ],
      "source": [
        "# Evaluating the trained model on the test data\n",
        "test_loss, test_accuracy = model.evaluate(test_data, test_labels)\n",
        "\n",
        "# Print test loss and accuracy\n",
        "print(f'Test Loss: {test_loss}')\n",
        "print(f'Test Accuracy: {test_accuracy}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "64BbG8Y62TsH"
      },
      "source": [
        "## Exercise 2: Describe What you did\n",
        "\n",
        "All the work you did leading up to your final model should be summarized in this section. This should be a logical and well-organized summary of the various experiments that were tried in **Lab 3 Part 2 - Task 2:Exercise 1**, and should be captured in **table format**. Upon reading this section I should understand what you tried, the reasoning behind trying it, any quantitative values that correspond to what you tried, and the results.\n",
        "\n",
        "See [this guide](https://www.datacamp.com/community/tutorials/markdown-in-jupyter-notebook) for how to format markdown cells in Jupyter notebooks."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sa8p0Nkj2TsI"
      },
      "source": [
        "<table style=\"width:20%\">\n",
        "<tr>\n",
        "<th><Number></th>\n",
        "<th><Change></th>\n",
        "<th><Reason></th>\n",
        "<th><Results></th>\n",
        "</tr>\n",
        "\n",
        "<tr>\n",
        "<td><1></td>\n",
        "<td><Add pooling layers></td>\n",
        "<td><\"To reduce the dimensions of the feature maps and by consequence the number of parameters to learn and the amount of computation performed in the network.\"></td>\n",
        "<td><\"0.52\"></td>\n",
        "</tr>\n",
        "\n",
        "\n",
        "</table>"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jkPmEz8GR-CH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "vC9hai03SAFD"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
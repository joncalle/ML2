{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "OWrEnyj3Ujom",
   "metadata": {
    "id": "OWrEnyj3Ujom"
   },
   "source": [
    "#**Lab 4 - Part 1** (30 Marks)\n",
    "\n",
    "Group 9:\n",
    "\n",
    "Danielle do Val Goncalves Tudeia - W0823569\n",
    "\n",
    "Fernanda Barbieri de Camargo - W0825882\n",
    "\n",
    "Jonathan Alberto Calle Zuniga - W0825959\n",
    "\n",
    "Jonathan Oteh - W0775057\n",
    "\n",
    "Luis Ramirez Fernandez - W0811391"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c46990b",
   "metadata": {
    "id": "5c46990b"
   },
   "source": [
    "## Hyperparameter tuning by hand (Manual Method)\n",
    "\n",
    "In this section, you will create a fully-connected neural network and then tune the hyperparameters by hand. To mix things up a little bit, we will use the **[Shoe, Sandal, and Boot](https://www.kaggle.com/datasets/hasibalmuzdadid/shoe-vs-sandal-vs-boot-dataset-15k-images)** dataset from Kaggle."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9909697",
   "metadata": {
    "id": "c9909697"
   },
   "source": [
    "### Import statements\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e05019ff",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e05019ff",
    "outputId": "926bf1cb-24b9-4cf5-e2f8-51305bb7c959"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "# TO DO: collect all needed import statements here\n",
    "\n",
    "# Data Overview\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Import libraries\n",
    "import os\n",
    "import pathlib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import seaborn as sns\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, Flatten, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers.experimental.preprocessing import Rescaling\n",
    "from tensorflow.keras.layers import Flatten\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62303511",
   "metadata": {
    "id": "62303511"
   },
   "source": [
    "### Get the data (10 Marks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c51dc4ae-1cdd-44b6-a0d2-2d855b2ef62d",
   "metadata": {
    "id": "c51dc4ae-1cdd-44b6-a0d2-2d855b2ef62d"
   },
   "outputs": [],
   "source": [
    "# TO DO: use 'image_dataset_from_directory' (making sure to also set the 'validation_split', 'subset', and 'seed' arguments)\n",
    "#        to create training and validation datasets. Set the appropriate image size by consulting the data documentation\n",
    "\n",
    "base_dir = pathlib.Path('/content/drive/MyDrive/Lab4ML2/Shoe vs Sandal vs Boot Dataset')\n",
    "\n",
    "image_size = (224, 224)\n",
    "batch_size = 32\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "mpvmcOmE8H03",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mpvmcOmE8H03",
    "outputId": "d2f4b12b-7899-41b2-c8c1-b681aa29d7e0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 15010 files belonging to 3 classes.\n",
      "Using 12008 files for training.\n",
      "Found 15010 files belonging to 3 classes.\n",
      "Using 3002 files for validation.\n"
     ]
    }
   ],
   "source": [
    "# prompt: calculate train_ds, val_ds\n",
    "\n",
    "train_ds = image_dataset_from_directory(\n",
    "    base_dir,\n",
    "    validation_split=0.2,\n",
    "    subset=\"training\",\n",
    "    seed=123,\n",
    "    image_size=image_size,\n",
    "    batch_size=batch_size,\n",
    ")\n",
    "\n",
    "val_ds = image_dataset_from_directory(\n",
    "    base_dir,\n",
    "    validation_split=0.2,\n",
    "    subset=\"validation\",\n",
    "    seed=123,\n",
    "    image_size=image_size,\n",
    "    batch_size=batch_size,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5e2061bc-c586-4ea8-ab96-06b4636c8d03",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5e2061bc-c586-4ea8-ab96-06b4636c8d03",
    "outputId": "9d789405-d003-4944-b9ec-6f3b43bbf6f6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 224, 224, 3)\n",
      "(32,)\n"
     ]
    }
   ],
   "source": [
    "for imgs, labs in train_ds:\n",
    "  print(imgs.shape)\n",
    "  print(labs.shape)\n",
    "  break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efc93e2b",
   "metadata": {
    "id": "efc93e2b"
   },
   "source": [
    "### Set hyperparameter values to test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "W-PnHrsIAb5V",
   "metadata": {
    "id": "W-PnHrsIAb5V"
   },
   "outputs": [],
   "source": [
    "# TO DO: create lists with 3 choices for each hyperparameter\n",
    "\n",
    "neuron_choices = [16, 32, 64]\n",
    "activations = ['relu', 'sigmoid', 'tanh']\n",
    "optimizers = ['adam', 'sgd', 'rmsprop']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2844460b-8579-4dbd-8491-105af9c52011",
   "metadata": {
    "id": "2844460b-8579-4dbd-8491-105af9c52011"
   },
   "source": [
    "### Create a function to build a model (5 Marks)\n",
    "\n",
    "Since we will need to create many models with the same structure, just with different hyperparameter values, we should create a function that will do this for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "96bc0613",
   "metadata": {
    "id": "96bc0613"
   },
   "outputs": [],
   "source": [
    "# TO DO: create a function to build a model using the functional API that includes rescaling, a single hidden layer, and an appropriate output layer\n",
    "\n",
    "def build_model(neurons, activation, optimizer):\n",
    "  inputs = keras.Input(shape=(224, 224, 3))\n",
    "  x = Flatten()(inputs)\n",
    "  x = Rescaling(1./255)(x)\n",
    "  x = Dense(neurons, activation=activation)(x)\n",
    "  outputs = Dense(3, activation='softmax')(x)\n",
    "  model = keras.Model(inputs, outputs)\n",
    "\n",
    "  return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c6481c0",
   "metadata": {
    "id": "8c6481c0",
    "tags": []
   },
   "source": [
    "### Test all combinations and save the best model (15 Marks)\n",
    "\n",
    "For each set of hyperparameters we will want to train the model and then save the best version of that model after training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "146cda12",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "146cda12",
    "outputId": "bec63aae-7a07-4066-b3ea-7df9c9d03026"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neurons: 16 / Act Function = relu / Optimizer: adam / Val_loss: 1.099 / Val_accu: 0.332\n",
      "Neurons: 16 / Act Function = relu / Optimizer: sgd / Val_loss: 1.099 / Val_accu: 0.333\n",
      "Neurons: 16 / Act Function = relu / Optimizer: rmsprop / Val_loss: 1.099 / Val_accu: 0.333\n",
      "Neurons: 16 / Act Function = sigmoid / Optimizer: adam / Val_loss: 1.099 / Val_accu: 0.333\n",
      "Neurons: 16 / Act Function = sigmoid / Optimizer: sgd / Val_loss: 0.961 / Val_accu: 0.708\n",
      "Neurons: 16 / Act Function = sigmoid / Optimizer: rmsprop / Val_loss: 1.099 / Val_accu: 0.329\n",
      "Neurons: 16 / Act Function = tanh / Optimizer: adam / Val_loss: 1.099 / Val_accu: 0.329\n",
      "Neurons: 16 / Act Function = tanh / Optimizer: sgd / Val_loss: 1.099 / Val_accu: 0.338\n",
      "Neurons: 16 / Act Function = tanh / Optimizer: rmsprop / Val_loss: 1.099 / Val_accu: 0.329\n",
      "Neurons: 32 / Act Function = relu / Optimizer: adam / Val_loss: 2.181 / Val_accu: 0.839\n",
      "Neurons: 32 / Act Function = relu / Optimizer: sgd / Val_loss: 1.099 / Val_accu: 0.333\n",
      "Neurons: 32 / Act Function = relu / Optimizer: rmsprop / Val_loss: 1.099 / Val_accu: 0.333\n",
      "Neurons: 32 / Act Function = sigmoid / Optimizer: adam / Val_loss: 1.099 / Val_accu: 0.329\n",
      "Neurons: 32 / Act Function = sigmoid / Optimizer: sgd / Val_loss: 0.737 / Val_accu: 0.646\n",
      "Neurons: 32 / Act Function = sigmoid / Optimizer: rmsprop / Val_loss: 1.099 / Val_accu: 0.338\n",
      "Neurons: 32 / Act Function = tanh / Optimizer: adam / Val_loss: 1.099 / Val_accu: 0.338\n",
      "Neurons: 32 / Act Function = tanh / Optimizer: sgd / Val_loss: 1.100 / Val_accu: 0.338\n",
      "Neurons: 32 / Act Function = tanh / Optimizer: rmsprop / Val_loss: 1.099 / Val_accu: 0.338\n",
      "Neurons: 64 / Act Function = relu / Optimizer: adam / Val_loss: 0.424 / Val_accu: 0.848\n",
      "Neurons: 64 / Act Function = relu / Optimizer: sgd / Val_loss: 1.099 / Val_accu: 0.333\n",
      "Neurons: 64 / Act Function = relu / Optimizer: rmsprop / Val_loss: 5.033 / Val_accu: 0.789\n",
      "Neurons: 64 / Act Function = sigmoid / Optimizer: adam / Val_loss: 1.099 / Val_accu: 0.338\n",
      "Neurons: 64 / Act Function = sigmoid / Optimizer: sgd / Val_loss: 0.470 / Val_accu: 0.814\n",
      "Neurons: 64 / Act Function = sigmoid / Optimizer: rmsprop / Val_loss: 1.099 / Val_accu: 0.338\n",
      "Neurons: 64 / Act Function = tanh / Optimizer: adam / Val_loss: 1.099 / Val_accu: 0.329\n",
      "Neurons: 64 / Act Function = tanh / Optimizer: sgd / Val_loss: 1.106 / Val_accu: 0.338\n",
      "Neurons: 64 / Act Function = tanh / Optimizer: rmsprop / Val_loss: 1.103 / Val_accu: 0.329\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "path = str('/content/drive/MyDrive/Lab4ML2/best_model.h5')\n",
    "\n",
    "for neurons in neuron_choices:\n",
    "    for activation in activations:\n",
    "        for optimizer in optimizers:\n",
    "            model = build_model(neurons, activation, optimizer) # build model\n",
    "            model.compile(\n",
    "                optimizer=optimizer,\n",
    "                loss='sparse_categorical_crossentropy',\n",
    "                metrics=['accuracy']) # compile model\n",
    "\n",
    "            callback = ModelCheckpoint(\n",
    "                filepath=path,\n",
    "                monitor=\"val_loss\",\n",
    "                save_best_only=True,\n",
    "                save_weights_only=True) #create callback (ModelCheckpoint)\n",
    "\n",
    "            model.fit(\n",
    "                train_ds,\n",
    "                validation_data=val_ds,\n",
    "                epochs=2,\n",
    "                callbacks=[callback],\n",
    "                verbose=0) #train model\n",
    "\n",
    "            # load the model that was saved as part of the callback\n",
    "\n",
    "            test_model = build_model(neurons, activation, optimizer) # create a model to test\n",
    "\n",
    "            test_model.load_weights(path) #load the saved weights\n",
    "\n",
    "            test_model.compile(\n",
    "                loss = 'sparse_categorical_crossentropy',\n",
    "                optimizer = optimizer,\n",
    "                metrics = ['accuracy']) #compile model\n",
    "\n",
    "            # calculate the validation loss and accuracy by evaluating the best model on the validation set\n",
    "            val_loss, val_accu = test_model.evaluate(val_ds, verbose = 0)\n",
    "\n",
    "            # print out hyperparameters and validation loss and accuracy\n",
    "\n",
    "            print(f\"Neurons: {neurons} / Act Function = {activation} / Optimizer: {optimizer} / Val_loss: {val_loss:.3f} / Val_accu: {val_accu:.3f}\")\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
